{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbvHKaxEybqP"
      },
      "source": [
        "### Data Wrangling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Un9RO-iWbD-8"
      },
      "outputs": [],
      "source": [
        "with open('train_neg_reviews.txt',encoding='utf-8') as f:\n",
        "  contents = f.read()\n",
        "  train_neg_reviews = [review for review in contents.split('\\n')]\n",
        "\n",
        "with open('train_pos_reviews.txt',encoding='utf-8') as f:\n",
        "  contents = f.read()\n",
        "  train_pos_reviews = [review for review in contents.split('\\n')]\n",
        "\n",
        "with open('test_neg_reviews.txt',encoding='utf-8') as f:\n",
        "  contents = f.read()\n",
        "  test_neg_reviews = [review for review in contents.split('\\n')]\n",
        "\n",
        "with open('train_pos_reviews.txt',encoding='utf-8') as f:\n",
        "  contents = f.read()\n",
        "  test_pos_reviews = [review for review in contents.split('\\n')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hsB6j0C2Nj7J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "reviews = train_neg_reviews + test_neg_reviews + train_pos_reviews + test_pos_reviews\n",
        "scores = [int(review.split('\\t')[0] or 3) for review in reviews]\n",
        "reviews_text = [''.join(review.split('\\t')[1:]) for review in reviews]\n",
        "classification = [0]*len(train_neg_reviews + test_neg_reviews) + [1]*len(train_pos_reviews + test_pos_reviews)\n",
        "df = pd.DataFrame({'review': reviews_text, 'score': scores, 'classification': classification})\n",
        "df = df.sample(frac=1, random_state=0) # shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9kCWCbdfniM",
        "outputId": "78fdad20-4daa-44ec-fbde-48c4449aa2b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TfidfVectorizer()"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(df.review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Z2A9aj52O70p"
      },
      "outputs": [],
      "source": [
        "tfidf_embeddings = vectorizer.transform(df.review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTKPXVGWf-Es"
      },
      "source": [
        "A random forest is a type of ensemble machine learning model that is made up of multiple decision trees. Ensemble models combine the predictions of multiple individual models to make more accurate predictions. In a random forest, each decision tree is trained on a random subset of the data, and the final prediction is made by averaging the predictions of all the individual decision trees.\n",
        "\n",
        "Here is an example of how to train a random forest using the scikit-learn library in Python:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hhuUKnzrPKyt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_embeddings, df.classification, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhFWIkRCyhRN"
      },
      "source": [
        "## Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-duzIGdfz_O",
        "outputId": "35aaf495-cc4f-459c-8118-e015f282e99d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9282057844893781"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a random forest classifier with 100 trees\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Train the model on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Score\n",
        "model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VetvszHcapRa",
        "outputId": "60d1e0a2-70e0-4d18-ba77-de4a1796dd93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94      4707\n",
            "           1       0.97      0.84      0.90      3107\n",
            "\n",
            "    accuracy                           0.93      7814\n",
            "   macro avg       0.94      0.91      0.92      7814\n",
            "weighted avg       0.93      0.93      0.93      7814\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcsq87hTzGVd"
      },
      "source": [
        "## Hyperparameter Searching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Hx8AcFm1kyaC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid for the model\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 100, 1000],\n",
        "    'max_depth': [5, 10, 50, 100],\n",
        "    'min_impurity_decrease': [0, 0.1, 1],\n",
        "    'max_features': [1, 10, 100, 1000, None]\n",
        "}\n",
        "\n",
        "model_grid = RandomForestClassifier()\n",
        "\n",
        "# Use GridSearchCV to search for the best hyperparameters\n",
        "clf = GridSearchCV(model_grid, param_grid, cv=5)\n",
        "\n",
        "\n",
        "# clf.fit(X, y)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "# print(f\"Best hyperparameters: {clf.best_params_}. Score: {clf.best_score_:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9IMavwz9gt-"
      },
      "source": [
        "## Contextual Polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VmLoGsk28vMk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Negative Words ['worst' 'bad' 'awful' 'boring' 'poor' 'waste' 'terrible' 'no' 'nothing'\n",
            " 'dull']\n",
            "Positive Words ['still' 'loved' 'today' 'fun' 'wonderful' 'amazing' 'perfect' 'excellent'\n",
            " 'best' 'great']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "feature_names = np.array(vectorizer.get_feature_names())\n",
        "sorted_coef_index = model.coef_[0].argsort()\n",
        "print(\"Negative Words\", feature_names[sorted_coef_index[:10]])\n",
        "print(\"Positive Words\", feature_names[sorted_coef_index[-10:]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCDzHErHDcNg"
      },
      "source": [
        "## More Models!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb0XoZpbgp5f",
        "outputId": "2edbf1f0-b7f0-4a77-c2b3-fc4c41bdc71c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8287688763757358"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Create a gradient boosting classifier\n",
        "clf = GradientBoostingClassifier()\n",
        "\n",
        "# Train the classifier on the data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on new data\n",
        "clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "AUb8MfvjyxIm"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23:22:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "Accuracy: 90.41%\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Create the XGBoost model\n",
        "model = xgb.XGBClassifier()\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1_NZUJmDoqE"
      },
      "source": [
        "## More Advanced Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8EzboyZEHsq",
        "outputId": "a8fdeb2a-9752-486e-ceac-25824c14af3d"
      },
      "outputs": [],
      "source": [
        "# !pip install openai\n",
        "# import openai\n",
        "# openai.api_key = # GET THIS FROM JOSIAH IF NEEDED\n",
        "# from openai.embeddings_utils import cosine_similarity, get_embeddings as _get_embeddings, get_embedding as _get_embedding\n",
        "# get_embeddings = lambda x: _get_embeddings(x, 'text-embedding-ada-002')\n",
        "# get_embedding = lambda x: _get_embedding(x, 'text-embedding-ada-002')\n",
        "# sub = df.iloc[:2000]\n",
        "# sub['ada_embeddings'] = get_embeddings(sub.review)\n",
        "# sub.to_csv('embedded_reviews.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ShIxCmLMe31y"
      },
      "outputs": [],
      "source": [
        "sub = pd.read_csv('embedded_reviews.csv')\n",
        "sub.ada_embeddings = sub.ada_embeddings.apply(eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYK4wy4UhfW5",
        "outputId": "df344335-d819-4bf1-fb5e-a6f760b02a09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 1536)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.array([emb for emb in sub.ada_embeddings.values])\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1isRWhAX2MH",
        "outputId": "3e2c1b50-9180-4a09-e49e-2a23cf98c3bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.878"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, sub.classification)\n",
        "model = RandomForestClassifier(max_depth=5)\n",
        "model.fit(X_train, y_train)\n",
        "model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZDarZWzZdSO",
        "outputId": "fc0a6784-9962-4037-a2f2-eab7bfc78d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88       256\n",
            "           1       0.86      0.90      0.88       244\n",
            "\n",
            "    accuracy                           0.88       500\n",
            "   macro avg       0.88      0.88      0.88       500\n",
            "weighted avg       0.88      0.88      0.88       500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7IzNKbEqiD1n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'max_depth': 10, 'max_features': 100, 'min_impurity_decrease': 0, 'n_estimators': 1000}. Score: 0.89\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid for the model\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 100, 1000],\n",
        "    'max_depth': [5, 10, 50, 100],\n",
        "    'min_impurity_decrease': [0, 0.1, 1],\n",
        "    'max_features': [1, 10, 100, 1000, None]\n",
        "}\n",
        "\n",
        "model_grid = RandomForestClassifier()\n",
        "\n",
        "# Use GridSearchCV to search for the best hyperparameters\n",
        "clf = GridSearchCV(model_grid, param_grid, cv=5)\n",
        "\n",
        "\n",
        "clf.fit(X, sub.classification)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(f\"Best hyperparameters: {clf.best_params_}. Score: {clf.best_score_:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mMCC3WniP9c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
