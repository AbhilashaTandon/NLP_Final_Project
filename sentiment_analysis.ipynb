{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling"
      ],
      "metadata": {
        "id": "PbvHKaxEybqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "root_dir = \"/content/gdrive/My Drive/NLP Sentiment Analysis\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TytpVVLzcVO8",
        "outputId": "220dada2-a32a-4fcf-d4f4-0f437593e0b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{root_dir}/train_neg_reviews.txt') as f:\n",
        "  contents = f.read()\n",
        "  train_neg_reviews = [review for review in contents.split('\\n')]\n",
        "\n",
        "with open(f'{root_dir}/train_pos_reviews.txt') as f:\n",
        "  contents = f.read()\n",
        "  train_pos_reviews = [review for review in contents.split('\\n')]\n",
        "\n",
        "with open(f'{root_dir}/test_neg_reviews.txt') as f:\n",
        "  contents = f.read()\n",
        "  test_neg_reviews = [review for review in contents.split('\\n')]\n",
        "\n",
        "with open(f'{root_dir}/test_pos_reviews.txt') as f:\n",
        "  contents = f.read()\n",
        "  test_pos_reviews = [review for review in contents.split('\\n')]"
      ],
      "metadata": {
        "id": "Un9RO-iWbD-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "reviews = train_neg_reviews + test_neg_reviews + train_pos_reviews + test_pos_reviews\n",
        "scores = [int(review.split('\\t')[0] or 3) for review in reviews]\n",
        "reviews_text = [''.join(review.split('\\t')[1:]) for review in reviews]\n",
        "classification = [0]*len(train_neg_reviews + test_neg_reviews) + [1]*len(train_pos_reviews + test_pos_reviews)\n",
        "df = pd.DataFrame({'review': reviews_text, 'score': scores, 'classification': classification})\n",
        "df = df.sample(frac=1, random_state=0) # shuffle"
      ],
      "metadata": {
        "id": "hsB6j0C2Nj7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(df.review)"
      ],
      "metadata": {
        "id": "K9kCWCbdfniM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78fdad20-4daa-44ec-fbde-48c4449aa2b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_embeddings = vectorizer.transform(df.review)"
      ],
      "metadata": {
        "id": "Z2A9aj52O70p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A random forest is a type of ensemble machine learning model that is made up of multiple decision trees. Ensemble models combine the predictions of multiple individual models to make more accurate predictions. In a random forest, each decision tree is trained on a random subset of the data, and the final prediction is made by averaging the predictions of all the individual decision trees.\n",
        "\n",
        "Here is an example of how to train a random forest using the scikit-learn library in Python:\n"
      ],
      "metadata": {
        "id": "vTKPXVGWf-Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_embeddings, df.classification, random_state=0)"
      ],
      "metadata": {
        "id": "hhuUKnzrPKyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Fitting"
      ],
      "metadata": {
        "id": "hhFWIkRCyhRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a random forest classifier with 100 trees\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Train the model on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Score\n",
        "model.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-duzIGdfz_O",
        "outputId": "35aaf495-cc4f-459c-8118-e015f282e99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8398037542662116"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VetvszHcapRa",
        "outputId": "60d1e0a2-70e0-4d18-ba77-de4a1796dd93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84      4691\n",
            "           1       0.84      0.83      0.84      4685\n",
            "\n",
            "    accuracy                           0.84      9376\n",
            "   macro avg       0.84      0.84      0.84      9376\n",
            "weighted avg       0.84      0.84      0.84      9376\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Searching"
      ],
      "metadata": {
        "id": "Dcsq87hTzGVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid for the model\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 100, 1000],\n",
        "    'max_depth': [5, 10, 50, 100],\n",
        "    'min_impurity_decrease': [0, 0.1, 1],\n",
        "    'max_features': [1, 10, 100, 1000, None]\n",
        "}\n",
        "\n",
        "model_grid = RandomForestClassifier()\n",
        "\n",
        "# Use GridSearchCV to search for the best hyperparameters\n",
        "clf = GridSearchCV(model_grid, param_grid, cv=5)\n",
        "\n",
        "\n",
        "# clf.fit(X, y)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "# print(f\"Best hyperparameters: {clf.best_params_}. Score: {clf.best_score_:.2f}\")"
      ],
      "metadata": {
        "id": "Hx8AcFm1kyaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contextual Polarity"
      ],
      "metadata": {
        "id": "p9IMavwz9gt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "feature_names = np.array(vectorizer.get_feature_names())\n",
        "sorted_coef_index = model.coef_[0].argsort()\n",
        "print(\"Negative Words\", feature_names[sorted_coef_index[:10]])\n",
        "print(\"Positive Words\", feature_names[sorted_coef_index[-10:]])"
      ],
      "metadata": {
        "id": "VmLoGsk28vMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More Models!"
      ],
      "metadata": {
        "id": "VCDzHErHDcNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Create a gradient boosting classifier\n",
        "clf = GradientBoostingClassifier()\n",
        "\n",
        "# Train the classifier on the data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on new data\n",
        "clf.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb0XoZpbgp5f",
        "outputId": "2edbf1f0-b7f0-4a77-c2b3-fc4c41bdc71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8095352371810255"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Create the XGBoost model\n",
        "model = xgb.XGBClassifier()\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "AUb8MfvjyxIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More Advanced Embeddings"
      ],
      "metadata": {
        "id": "-1_NZUJmDoqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install openai\n",
        "# import openai\n",
        "# openai.api_key = # GET THIS FROM JOSIAH IF NEEDED\n",
        "# from openai.embeddings_utils import cosine_similarity, get_embeddings as _get_embeddings, get_embedding as _get_embedding\n",
        "# get_embeddings = lambda x: _get_embeddings(x, 'text-embedding-ada-002')\n",
        "# get_embedding = lambda x: _get_embedding(x, 'text-embedding-ada-002')\n",
        "# sub = df.iloc[:2000]\n",
        "# sub['ada_embeddings'] = get_embeddings(sub.review)\n",
        "# sub.to_csv('embedded_reviews.csv', index=False)"
      ],
      "metadata": {
        "id": "m8EzboyZEHsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8fdeb2a-9752-486e-ceac-25824c14af3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-203-de174832dea2>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sub['ada_embeddings'] = get_embeddings(sub.review)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.read_csv(root_dir + '/embedded_reviews.csv')\n",
        "sub.ada_embeddings = sub.ada_embeddings.apply(eval)"
      ],
      "metadata": {
        "id": "ShIxCmLMe31y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([emb for emb in sub.ada_embeddings.values])\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYK4wy4UhfW5",
        "outputId": "df344335-d819-4bf1-fb5e-a6f760b02a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 1536)"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, sub.classification)\n",
        "model = RandomForestClassifier(max_depth=5)\n",
        "model.fit(X_train, y_train)\n",
        "model.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1isRWhAX2MH",
        "outputId": "3e2c1b50-9180-4a09-e49e-2a23cf98c3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZDarZWzZdSO",
        "outputId": "fc0a6784-9962-4037-a2f2-eab7bfc78d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89       237\n",
            "           1       0.92      0.87      0.89       263\n",
            "\n",
            "    accuracy                           0.89       500\n",
            "   macro avg       0.89      0.89      0.89       500\n",
            "weighted avg       0.89      0.89      0.89       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid for the model\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 100, 1000],\n",
        "    'max_depth': [5, 10, 50, 100],\n",
        "    'min_impurity_decrease': [0, 0.1, 1],\n",
        "    'max_features': [1, 10, 100, 1000, None]\n",
        "}\n",
        "\n",
        "model_grid = RandomForestClassifier()\n",
        "\n",
        "# Use GridSearchCV to search for the best hyperparameters\n",
        "clf = GridSearchCV(model_grid, param_grid, cv=5)\n",
        "\n",
        "\n",
        "clf.fit(X, sub.classification)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(f\"Best hyperparameters: {clf.best_params_}. Score: {clf.best_score_:.2f}\")"
      ],
      "metadata": {
        "id": "7IzNKbEqiD1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-mMCC3WniP9c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}